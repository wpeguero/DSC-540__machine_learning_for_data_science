{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble learning is a general approach where the combination of related methods provides better predictions or improves overall performance. Some real-world examples of its use include the Netflix Challenge, gene classification, image segmentation, and video retrieval.\n",
    "\n",
    "In this assignment, you will implement ensemble learning, combining a variety of learning methods such as max voting, averaging, weighted averaging, bagging, boosting (gradient boosting, random forest, XGBoost, etc.), stacking, blending, and other variations.\n",
    "\n",
    "You will have the freedom to choose between implementing classification or regression machine learning, or a combination of the two, so choose your ensemble techniques accordingly.\n",
    "\n",
    "1. Access the \"UCI Machine Learning Repository,\" located in the topic Resources. Note: There are about 120 data sets that are suitable for use in a clustering task. For this part of the exercise, you must choose one of these datasets, provided it includes at least 10 attributes and 10,000 instances\n",
    "2. Ensure that the datasets are suitable for clustering using this method.\n",
    "3. You may search for data in other repositories, such as Data.gov or Kaggle.\n",
    "\n",
    "For your selected dataset, build an ensemble model as follows:\n",
    "\n",
    "1. Explain the dataset and the type of information you wish to gain by applying an ensemble method.\n",
    "1. Explain the ensemble components and how you will be using it in your analysis (list the steps, intuition behind the mathematical representation, and address its assumptions). Specifically, which of max voting, averaging, weighted averaging, bagging, boosting (gradient boosting, random forest, XGBoost, etc.), stacking, blending, and/or other variations have you chosen, and why.\n",
    "1. Import necessary libraries, then read the dataset into a data frame and perform initial statistical exploration.\n",
    "1. Clean the data and address unusual phenomena (e.g., normalization, feature scaling, outliers); use illustrative diagrams and plots and explain them.\n",
    "1. Formulate two questions that can be answered by employing the ensemble learning\n",
    "1. If appropriate and relevant to your model, split the data into training and testing sets.\n",
    "1. Provide a diagram that illustrates how the ensemble components are combined into one learning model.\n",
    "1. Implement and execute the ensemble learning model. Explain the intuition behind each mathematical step.\n",
    "1. Answer the questions you formulated using the results obtained from executing the ensemble model.\n",
    "1. Interpret the predictions made by the model in the context of the questions you asked.\n",
    "1. Validate your model using relevant validation metrics such as a confusion matrix, accuracy score, ROC-AUC curves, and k-fold cross validation. Then, explain the results.\n",
    "1. Explain how ensemble system reduced the variance.\n",
    "1. Include all mathematical formulas used and graphs representing the final outcomes.\n",
    "\n",
    "Prepare a comprehensive technical report as a markdown document or Jupyter notebook, including all code, code comments, all outputs, plots, and analysis. Make sure the project documentation contains a) problem statement, b) algorithm of the solution, c) analysis of the findings, and d) references."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Currently, 99% (3.96 Billion) of four billion species that have ever lived on this earth have gone extinct. even now, there are currently multiple species that are at risk of becoming extinct. This provides one with an environment where there may be multiple variants of a single species that has gone extinct while unidentified. Through the use of genetic material and data on current living species, one is able to determine what the closest rewlative the extinct species may have currently alive. Knowing the relationship between extinct and current species allows one to understand how a species has come to adapt to it's environment (whether it be through regression or developing a new mutation that allowed the current species to thrive in it's environment).\n",
    "\n",
    "From the codon usage dataset, one hopes to extract enough information to determine whether a certain species belongs to a certain type of species, family, kingom, etc. At the moment, the data set can provide one with the DNA Type of the species as well as the kingdom that the species belongs in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wpegu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNAtype</th>\n",
       "      <th>SpeciesID</th>\n",
       "      <th>Ncodons</th>\n",
       "      <th>UUA</th>\n",
       "      <th>UUG</th>\n",
       "      <th>CUU</th>\n",
       "      <th>CUC</th>\n",
       "      <th>CUA</th>\n",
       "      <th>CUG</th>\n",
       "      <th>AUU</th>\n",
       "      <th>...</th>\n",
       "      <th>CGG</th>\n",
       "      <th>AGA</th>\n",
       "      <th>AGG</th>\n",
       "      <th>GAU</th>\n",
       "      <th>GAC</th>\n",
       "      <th>GAA</th>\n",
       "      <th>GAG</th>\n",
       "      <th>UAA</th>\n",
       "      <th>UAG</th>\n",
       "      <th>UGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>1.302800e+04</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "      <td>13028.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.367209</td>\n",
       "      <td>130451.105926</td>\n",
       "      <td>7.960576e+04</td>\n",
       "      <td>0.020637</td>\n",
       "      <td>0.014104</td>\n",
       "      <td>0.017820</td>\n",
       "      <td>0.018288</td>\n",
       "      <td>0.019044</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.009929</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.024178</td>\n",
       "      <td>0.021164</td>\n",
       "      <td>0.028290</td>\n",
       "      <td>0.021683</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.006178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.688726</td>\n",
       "      <td>124787.086107</td>\n",
       "      <td>7.197010e+05</td>\n",
       "      <td>0.020709</td>\n",
       "      <td>0.009280</td>\n",
       "      <td>0.010586</td>\n",
       "      <td>0.014572</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.017507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>0.008574</td>\n",
       "      <td>0.006387</td>\n",
       "      <td>0.013828</td>\n",
       "      <td>0.013041</td>\n",
       "      <td>0.014342</td>\n",
       "      <td>0.015018</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.010344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>28850.750000</td>\n",
       "      <td>1.602000e+03</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.010890</td>\n",
       "      <td>0.007830</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.016360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.012380</td>\n",
       "      <td>0.011860</td>\n",
       "      <td>0.017360</td>\n",
       "      <td>0.009710</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>81971.500000</td>\n",
       "      <td>2.927500e+03</td>\n",
       "      <td>0.015260</td>\n",
       "      <td>0.013360</td>\n",
       "      <td>0.016130</td>\n",
       "      <td>0.014560</td>\n",
       "      <td>0.009685</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.025475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.009270</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.025420</td>\n",
       "      <td>0.019070</td>\n",
       "      <td>0.026085</td>\n",
       "      <td>0.020540</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.001130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>222891.250000</td>\n",
       "      <td>9.120000e+03</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>0.019810</td>\n",
       "      <td>0.022730</td>\n",
       "      <td>0.025112</td>\n",
       "      <td>0.017245</td>\n",
       "      <td>0.024315</td>\n",
       "      <td>0.038113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007150</td>\n",
       "      <td>0.015922</td>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.034190</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.031122</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.002890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>465364.000000</td>\n",
       "      <td>4.066258e+07</td>\n",
       "      <td>0.151330</td>\n",
       "      <td>0.101190</td>\n",
       "      <td>0.089780</td>\n",
       "      <td>0.100350</td>\n",
       "      <td>0.163920</td>\n",
       "      <td>0.107370</td>\n",
       "      <td>0.154060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055540</td>\n",
       "      <td>0.098830</td>\n",
       "      <td>0.058430</td>\n",
       "      <td>0.185660</td>\n",
       "      <td>0.113840</td>\n",
       "      <td>0.144890</td>\n",
       "      <td>0.158550</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.025610</td>\n",
       "      <td>0.106700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DNAtype      SpeciesID       Ncodons           UUA           UUG  \\\n",
       "count  13028.000000   13028.000000  1.302800e+04  13028.000000  13028.000000   \n",
       "mean       0.367209  130451.105926  7.960576e+04      0.020637      0.014104   \n",
       "std        0.688726  124787.086107  7.197010e+05      0.020709      0.009280   \n",
       "min        0.000000       7.000000  1.000000e+03      0.000000      0.000000   \n",
       "25%        0.000000   28850.750000  1.602000e+03      0.005610      0.007108   \n",
       "50%        0.000000   81971.500000  2.927500e+03      0.015260      0.013360   \n",
       "75%        1.000000  222891.250000  9.120000e+03      0.029485      0.019810   \n",
       "max       12.000000  465364.000000  4.066258e+07      0.151330      0.101190   \n",
       "\n",
       "                CUU           CUC           CUA           CUG           AUU  \\\n",
       "count  13028.000000  13028.000000  13028.000000  13028.000000  13028.000000   \n",
       "mean       0.017820      0.018288      0.019044      0.018450      0.028352   \n",
       "std        0.010586      0.014572      0.024250      0.016578      0.017507   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.010890      0.007830      0.005307      0.007180      0.016360   \n",
       "50%        0.016130      0.014560      0.009685      0.012800      0.025475   \n",
       "75%        0.022730      0.025112      0.017245      0.024315      0.038113   \n",
       "max        0.089780      0.100350      0.163920      0.107370      0.154060   \n",
       "\n",
       "       ...           CGG           AGA           AGG           GAU  \\\n",
       "count  ...  13028.000000  13028.000000  13028.000000  13028.000000   \n",
       "mean   ...      0.005454      0.009929      0.006422      0.024178   \n",
       "std    ...      0.006605      0.008574      0.006387      0.013828   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.001220      0.001690      0.001170      0.012380   \n",
       "50%    ...      0.003530      0.009270      0.004545      0.025420   \n",
       "75%    ...      0.007150      0.015922      0.010250      0.034190   \n",
       "max    ...      0.055540      0.098830      0.058430      0.185660   \n",
       "\n",
       "                GAC           GAA           GAG           UAA           UAG  \\\n",
       "count  13028.000000  13028.000000  13028.000000  13028.000000  13028.000000   \n",
       "mean       0.021164      0.028290      0.021683      0.001645      0.000592   \n",
       "std        0.013041      0.014342      0.015018      0.001834      0.000907   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.011860      0.017360      0.009710      0.000560      0.000000   \n",
       "50%        0.019070      0.026085      0.020540      0.001380      0.000420   \n",
       "75%        0.027690      0.036800      0.031122      0.002370      0.000830   \n",
       "max        0.113840      0.144890      0.158550      0.045200      0.025610   \n",
       "\n",
       "                UGA  \n",
       "count  13028.000000  \n",
       "mean       0.006178  \n",
       "std        0.010344  \n",
       "min        0.000000  \n",
       "25%        0.000410  \n",
       "50%        0.001130  \n",
       "75%        0.002890  \n",
       "max        0.106700  \n",
       "\n",
       "[8 rows x 65 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df__codons = pd.read_csv(r'codon_usage_dataset/codon_usage.csv')\n",
    "df__codons.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "Now that the data has been uploaded, one should be able to process the data into a more functional format. The first change to make is convert the *Kingdom* feature into it's categorical version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source(s):\n",
    "\n",
    "- https://ourworldindata.org/extinctions\n",
    "- https://www.sciencedirect.com/science/article/abs/pii/S1673852721001855"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "381354fdf2db71db833037bd920d0e1d9b0c7ba1f03ade08c697116913672196"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
